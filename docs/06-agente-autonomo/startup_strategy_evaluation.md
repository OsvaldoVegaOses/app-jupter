# EvaluaciÃ³n EstratÃ©gica: Lecciones de Startups para APP_Jupter

**Fecha:** 7 Enero 2026  
**Objetivo:** Evaluar valor e implementaciÃ³n de features inspirados en Hebbia, Elicit, Devin y LangGraph

---

## Resumen Ejecutivo

| Concepto | Fuente | Valor | Esfuerzo | Prioridad |
|----------|--------|-------|----------|-----------|
| **Matrix UI** | Hebbia | ğŸ”¥ Muy Alto | 3 semanas | ğŸ”´ P1 |
| **Panel de Observabilidad** | Devin | ğŸ”¥ Muy Alto | 2 semanas | ğŸ”´ P1 |
| **Linkage Estricto** | Elicit | âœ… Existente | - | âœ… Hecho |
| **LangGraph Orchestration** | LangChain | ğŸŸ¡ Alto | 4 semanas | ğŸŸ¡ P2 |
| **DeepSeek R1 Integration** | DeepSeek | ğŸ’° Costo muy bajo | 1 semana | ğŸ”´ P1 |

---

## 1. Matrix UI (Inspirado en Hebbia)

### Concepto Original
> "En lugar de chatear uno a uno, el usuario define 5 cÃ³digos (columnas) y el Agente llena la tabla para las 50 entrevistas (filas) automÃ¡ticamente."

### Valor para APP_Jupter

| Aspecto | Impacto |
|---------|---------|
| **Escalabilidad** | Procesar 50 entrevistas en paralelo vs una por una |
| **Comparabilidad** | Ver todos los cÃ³digos side-by-side |
| **Eficiencia** | Reducir tiempo de codificaciÃ³n 10x |
| **Rigor metodolÃ³gico** | Applies misma heurÃ­stica a todas las entrevistas |

### ImplementaciÃ³n TÃ©cnica

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MATRIX CODING UI                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Columnas = CategorÃ­as/CÃ³digos a Buscar                        â”‚
â”‚  â”œâ”€â”€ "Escasez hÃ­drica"                                         â”‚
â”‚  â”œâ”€â”€ "Conflicto institucional"                                 â”‚
â”‚  â”œâ”€â”€ "Resiliencia comunitaria"                                 â”‚
â”‚  â””â”€â”€ "Soluciones tÃ©cnicas"                                     â”‚
â”‚                                                                 â”‚
â”‚  Filas = Entrevistas                                           â”‚
â”‚  â”œâ”€â”€ Entrevista_Alcalde.docx                                   â”‚
â”‚  â”œâ”€â”€ Entrevista_Vecino_1.docx                                  â”‚
â”‚  â”œâ”€â”€ Entrevista_ONG.docx                                       â”‚
â”‚  â””â”€â”€ ...                                                       â”‚
â”‚                                                                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚              â”‚ Escasez  â”‚ Conflicto â”‚Resilienciaâ”‚ TÃ©cnicas â”‚   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ Alcalde   â”‚ 3 citas  â”‚ 5 citas   â”‚ 1 cita    â”‚ 2 citas  â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ Vecino_1  â”‚ 7 citas  â”‚ 0         â”‚ 4 citas   â”‚ 0        â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ ONG       â”‚ 2 citas  â”‚ 8 citas   â”‚ 6 citas   â”‚ 3 citas  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  [Click celda] â†’ Expandir citas con fragmentos originales      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes a Crear

#### Frontend: `MatrixCodingPanel.tsx`

```typescript
interface MatrixCell {
  archivo: string;
  codigo: string;
  citas: Array<{
    fragmento_id: string;
    texto: string;
    score: number;
  }>;
  count: number;
}

interface MatrixRow {
  archivo: string;
  cells: Record<string, MatrixCell>;
}

function MatrixCodingPanel({ project }: { project: string }) {
  const [codes, setCodes] = useState<string[]>(["escasez", "conflicto"]);
  const [matrix, setMatrix] = useState<MatrixRow[]>([]);
  const [loading, setLoading] = useState(false);
  const [expandedCell, setExpandedCell] = useState<MatrixCell | null>(null);
  
  const handleFillMatrix = async () => {
    setLoading(true);
    const result = await apiFetch('/api/matrix/fill', {
      method: 'POST',
      body: JSON.stringify({ project, codes })
    });
    setMatrix(result.matrix);
    setLoading(false);
  };
  
  return (
    <div className="matrix-panel">
      {/* Header: Code columns */}
      <div className="matrix-header">
        {codes.map(code => (
          <input 
            key={code} 
            value={code} 
            onChange={e => updateCode(code, e.target.value)}
          />
        ))}
        <button onClick={() => setCodes([...codes, ''])}>+ CÃ³digo</button>
      </div>
      
      {/* Grid */}
      <table className="matrix-grid">
        <thead>
          <tr>
            <th>Entrevista</th>
            {codes.map(code => <th key={code}>{code}</th>)}
          </tr>
        </thead>
        <tbody>
          {matrix.map(row => (
            <tr key={row.archivo}>
              <td>{row.archivo}</td>
              {codes.map(code => (
                <td 
                  key={code}
                  className={getCellClass(row.cells[code]?.count)}
                  onClick={() => setExpandedCell(row.cells[code])}
                >
                  {row.cells[code]?.count || 0}
                </td>
              ))}
            </tr>
          ))}
        </tbody>
      </table>
      
      {/* Fill button */}
      <button onClick={handleFillMatrix} disabled={loading}>
        {loading ? 'Llenando matriz...' : 'ğŸ”„ Llenar Matriz con IA'}
      </button>
      
      {/* Expanded cell modal */}
      {expandedCell && (
        <CellDetailModal 
          cell={expandedCell} 
          onClose={() => setExpandedCell(null)}
        />
      )}
    </div>
  );
}
```

#### Backend: `/api/matrix/fill`

```python
@router.post("/api/matrix/fill")
async def fill_coding_matrix(
    request: MatrixFillRequest,
    clients: ServiceClients = Depends(get_service_clients)
):
    """
    Llena matriz de codificaciÃ³n usando bÃºsqueda semÃ¡ntica.
    
    Para cada (entrevista, cÃ³digo):
    1. Buscar en Qdrant fragmentos relevantes
    2. Filtrar por archivo
    3. Retornar top N citas
    """
    matrix = []
    
    # Obtener lista de archivos
    interviews = list_interviews_summary(clients.postgres, request.project)
    
    for interview in interviews:
        row = {"archivo": interview["archivo"], "cells": {}}
        
        for code in request.codes:
            # BÃºsqueda semÃ¡ntica por cÃ³digo
            results = search_similar_qdrant(
                clients.qdrant,
                query=code,
                project=request.project,
                filters={"archivo": interview["archivo"]},
                limit=10
            )
            
            row["cells"][code] = {
                "citas": [
                    {
                        "fragmento_id": r.id,
                        "texto": r.payload["text"][:200],
                        "score": r.score
                    }
                    for r in results
                    if r.score > 0.5  # Threshold
                ],
                "count": len([r for r in results if r.score > 0.5])
            }
        
        matrix.append(row)
    
    return {"matrix": matrix}
```

### Esfuerzo Estimado: **3 semanas**
- Frontend: 2 semanas (nuevo componente complejo)
- Backend: 1 semana (combina endpoints existentes)

---

## 2. Panel de Observabilidad (Inspirado en Devin)

### Concepto Original
> "Tu interfaz deberÃ­a tener un 'Panel de Pensamiento'. Cuando el agente estÃ© haciendo Link Prediction o SaturaciÃ³n, no muestres un spinner girando. Muestra los logs."

### Valor para APP_Jupter

| Aspecto | Impacto |
|---------|---------|
| **Confianza** | Usuario ve exactamente quÃ© hace la IA |
| **Debugging** | Identificar problemas rÃ¡pidamente |
| **Transparencia metodolÃ³gica** | Documenta decisiones del agente |
| **EducaciÃ³n** | Usuario aprende el proceso de GT |

### ImplementaciÃ³n TÃ©cnica

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 AGENT THINKING PANEL                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ğŸ“Š PLAN                                                 â”‚  â”‚
â”‚  â”‚ â”œâ”€â”€ Status: Etapa 3 (CodificaciÃ³n Abierta)             â”‚  â”‚
â”‚  â”‚ â”œâ”€â”€ Entrevistas sin codificar: 12                      â”‚  â”‚
â”‚  â”‚ â””â”€â”€ PrÃ³xima acciÃ³n: run_open_coding                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ âš¡ ACCIÃ“N EN CURSO                                      â”‚  â”‚
â”‚  â”‚ â€¢ Procesando: Entrevista_Vecino_3.docx                 â”‚  â”‚
â”‚  â”‚ â€¢ Fragmentos analizados: 34/52                         â”‚  â”‚
â”‚  â”‚ â€¢ CÃ³digos detectados: 8 nuevos, 4 duplicados           â”‚  â”‚
â”‚  â”‚   â”œâ”€â”€ escasez_agua (nuevo)                             â”‚  â”‚
â”‚  â”‚   â”œâ”€â”€ corte_suministro â†’ fusionado con escasez_agua   â”‚  â”‚
â”‚  â”‚   â””â”€â”€ conflicto_vecinal (nuevo)                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ğŸ“ˆ MÃ‰TRICAS                                             â”‚  â”‚
â”‚  â”‚ â€¢ SaturaciÃ³n: 67% (medium)                             â”‚  â”‚
â”‚  â”‚ â€¢ Linkage Rate: 94.2%                                  â”‚  â”‚
â”‚  â”‚ â€¢ Duplicados pendientes: 3                             â”‚  â”‚
â”‚  â”‚ â€¢ PageRank top: "gobernanza_local" (0.87)              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ğŸ“œ REASONING LOG                                        â”‚  â”‚
â”‚  â”‚ 15:42:01 [PLAN] DetectÃ© 12 entrevistas sin cÃ³digos     â”‚  â”‚
â”‚  â”‚ 15:42:03 [ACT] Iniciando run_open_coding para lote 1   â”‚  â”‚
â”‚  â”‚ 15:42:15 [OBSERVE] 8 cÃ³digos generados, 4 duplicados   â”‚  â”‚
â”‚  â”‚ 15:42:16 [ACT] deduplicate_codes(threshold=0.85)       â”‚  â”‚
â”‚  â”‚ 15:42:18 [REFLECT] FusionÃ© "corte" con "escasez"       â”‚  â”‚
â”‚  â”‚          porque comparten 91% vecindad en grafo        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes a Crear

#### WebSocket para streaming de logs

```python
# backend/routers/agent_ws.py

from fastapi import WebSocket
import asyncio

connected_clients: Dict[str, WebSocket] = {}

@router.websocket("/ws/agent/{project_id}")
async def agent_websocket(websocket: WebSocket, project_id: str):
    await websocket.accept()
    connected_clients[project_id] = websocket
    
    try:
        while True:
            # Keep connection alive
            await asyncio.sleep(30)
            await websocket.send_json({"type": "ping"})
    except:
        del connected_clients[project_id]

async def broadcast_agent_log(project_id: str, log: Dict):
    """EnvÃ­a log a todos los clientes conectados al proyecto."""
    if project_id in connected_clients:
        await connected_clients[project_id].send_json(log)

# Uso en el agente:
async def run_open_coding(project_id, file_ids):
    await broadcast_agent_log(project_id, {
        "type": "action",
        "stage": "ACT",
        "message": f"Iniciando codificaciÃ³n de {len(file_ids)} archivos"
    })
    
    for i, file_id in enumerate(file_ids):
        await broadcast_agent_log(project_id, {
            "type": "progress",
            "current": i + 1,
            "total": len(file_ids),
            "file": file_id
        })
        # ... procesamiento ...
    
    await broadcast_agent_log(project_id, {
        "type": "result",
        "codes_new": 8,
        "codes_merged": 4
    })
```

#### Frontend: `AgentThinkingPanel.tsx`

```typescript
function AgentThinkingPanel({ project }: { project: string }) {
  const [logs, setLogs] = useState<AgentLog[]>([]);
  const [metrics, setMetrics] = useState<AgentMetrics | null>(null);
  const [currentAction, setCurrentAction] = useState<string | null>(null);
  
  useEffect(() => {
    const ws = new WebSocket(`ws://localhost:8000/ws/agent/${project}`);
    
    ws.onmessage = (event) => {
      const data = JSON.parse(event.data);
      
      if (data.type === 'action') {
        setCurrentAction(data.message);
      } else if (data.type === 'progress') {
        setMetrics(prev => ({ ...prev, progress: data }));
      } else if (data.type === 'log') {
        setLogs(prev => [...prev, data].slice(-50)); // Keep last 50
      }
    };
    
    return () => ws.close();
  }, [project]);
  
  return (
    <aside className="agent-thinking-panel">
      <section className="panel-plan">
        <h4>ğŸ“Š PLAN</h4>
        <StatusDisplay project={project} />
      </section>
      
      <section className="panel-action">
        <h4>âš¡ ACCIÃ“N EN CURSO</h4>
        {currentAction ? (
          <div className="action-current">{currentAction}</div>
        ) : (
          <div className="action-idle">Esperando...</div>
        )}
        {metrics?.progress && (
          <ProgressBar 
            current={metrics.progress.current} 
            total={metrics.progress.total}
          />
        )}
      </section>
      
      <section className="panel-metrics">
        <h4>ğŸ“ˆ MÃ‰TRICAS</h4>
        <MetricsGrid project={project} />
      </section>
      
      <section className="panel-logs">
        <h4>ğŸ“œ REASONING LOG</h4>
        <div className="logs-container">
          {logs.map((log, i) => (
            <LogEntry key={i} log={log} />
          ))}
        </div>
      </section>
    </aside>
  );
}
```

### Esfuerzo Estimado: **2 semanas**
- WebSocket backend: 3 dÃ­as
- Frontend panel: 1 semana
- IntegraciÃ³n con agente: 4 dÃ­as

---

## 3. Linkage Estricto (Inspirado en Elicit)

### Concepto Original
> "MantÃ©n el hipervÃ­nculo estricto a la cita original (tu fragment_id)."

### Estado Actual: âœ… YA IMPLEMENTADO

APP_Jupter ya tiene esto:

| Feature | ImplementaciÃ³n Existente |
|---------|--------------------------|
| `fragment_id` Ãºnico | UUID en `entrevista_fragmentos` |
| Linkage en cÃ³digos | `analisis_codigos_abiertos.fragmento_id` |
| ValidaciÃ³n | `validate_citation_integrity()` en analysis.py |
| Linkage Rate | MÃ©trica calculada en `/api/coding/stats` |

### Mejora Sugerida: VisualizaciÃ³n de Linkage

```typescript
// Componente que muestra el fragmento original al hover sobre cualquier cita
function CitationLink({ fragmentId }: { fragmentId: string }) {
  const [fragment, setFragment] = useState<Fragment | null>(null);
  
  return (
    <Tooltip 
      content={
        <div className="citation-preview">
          <blockquote>{fragment?.text}</blockquote>
          <footer>
            ğŸ“„ {fragment?.archivo} | par_idx {fragment?.fragmento_idx}
          </footer>
        </div>
      }
    >
      <span className="citation-id">[{fragmentId.slice(0, 8)}...]</span>
    </Tooltip>
  );
}
```

---

## 4. LangGraph Orchestration

### Concepto Original
> "LangGraph te permite definir el flujo como un Grafo de Estados (StateGraph)."

### Valor para APP_Jupter

| Aspecto | Impacto |
|---------|---------|
| **Robustez** | Manejo de errores y reintentos built-in |
| **Checkpoints** | Pausar/resumir ejecuciÃ³n sin perder estado |
| **Branching** | Condicionales complejos (saturaciÃ³n, integridad) |
| **Observabilidad** | Tracing nativo compatible con LangSmith |

### ImplementaciÃ³n TÃ©cnica

```python
# app/agent_graph.py

from langgraph.graph import StateGraph, END
from typing import TypedDict, Optional

class GTState(TypedDict):
    project_id: str
    current_stage: str
    interviews_pending: list[str]
    codes_count: int
    saturation_level: str  # "low" | "medium" | "high"
    integrity_passed: bool
    memos: list[str]
    errors: list[str]

def check_status(state: GTState) -> GTState:
    """Nodo: Verifica estado del proyecto."""
    status = get_project_status(state["project_id"])
    state["current_stage"] = status["current_stage"]
    state["interviews_pending"] = status["uncoded_interviews"]
    return state

def run_coding(state: GTState) -> GTState:
    """Nodo: Ejecuta codificaciÃ³n abierta."""
    results = run_open_coding(
        state["project_id"], 
        state["interviews_pending"][:5]  # Batch de 5
    )
    state["codes_count"] += results["new_codes"]
    state["interviews_pending"] = state["interviews_pending"][5:]
    return state

def deduplicate(state: GTState) -> GTState:
    """Nodo: Fusiona cÃ³digos duplicados."""
    results = deduplicate_codes(state["project_id"], threshold=0.85)
    state["codes_count"] -= results["merged_count"]
    return state

def check_saturation(state: GTState) -> GTState:
    """Nodo: EvalÃºa saturaciÃ³n teÃ³rica."""
    saturation = get_saturation_status(state["project_id"])
    state["saturation_level"] = saturation["status"]
    return state

def validate_integrity(state: GTState) -> GTState:
    """Nodo: Valida integridad del grafo."""
    integrity = check_evidence_integrity(state["project_id"])
    state["integrity_passed"] = integrity["passed"]
    state["errors"].extend(integrity.get("errors", []))
    return state

def generate_report(state: GTState) -> GTState:
    """Nodo: Genera informe final."""
    report = build_final_report(state["project_id"])
    return state

def should_continue_coding(state: GTState) -> str:
    """DecisiÃ³n: Â¿MÃ¡s codificaciÃ³n necesaria?"""
    if state["interviews_pending"]:
        return "coding"  # MÃ¡s entrevistas por procesar
    return "saturation"  # Verificar saturaciÃ³n

def should_generate_report(state: GTState) -> str:
    """DecisiÃ³n: Â¿Listo para reporte?"""
    if state["saturation_level"] == "high" and state["integrity_passed"]:
        return "report"
    elif state["saturation_level"] == "low":
        return "discovery"  # Necesita mÃ¡s datos
    return "fix_integrity"  # Arreglar problemas

# Construir el grafo
workflow = StateGraph(GTState)

# Agregar nodos
workflow.add_node("check_status", check_status)
workflow.add_node("coding", run_coding)
workflow.add_node("deduplicate", deduplicate)
workflow.add_node("saturation", check_saturation)
workflow.add_node("integrity", validate_integrity)
workflow.add_node("report", generate_report)

# Agregar edges
workflow.set_entry_point("check_status")
workflow.add_edge("check_status", "coding")
workflow.add_edge("coding", "deduplicate")
workflow.add_conditional_edges(
    "deduplicate",
    should_continue_coding,
    {
        "coding": "coding",
        "saturation": "saturation"
    }
)
workflow.add_edge("saturation", "integrity")
workflow.add_conditional_edges(
    "integrity",
    should_generate_report,
    {
        "report": "report",
        "discovery": "check_status",  # Loop back
        "fix_integrity": "coding"
    }
)
workflow.add_edge("report", END)

# Compilar
app = workflow.compile()

# Ejecutar
async def run_gt_pipeline(project_id: str):
    initial_state = GTState(
        project_id=project_id,
        current_stage="",
        interviews_pending=[],
        codes_count=0,
        saturation_level="low",
        integrity_passed=False,
        memos=[],
        errors=[]
    )
    
    final_state = await app.ainvoke(initial_state)
    return final_state
```

### Diagrama del Grafo

```mermaid
graph TD
    A[check_status] --> B[coding]
    B --> C[deduplicate]
    C --> D{Â¿MÃ¡s entrevistas?}
    D -->|SÃ­| B
    D -->|No| E[saturation]
    E --> F[integrity]
    F --> G{Â¿Listo para reporte?}
    G -->|SaturaciÃ³n alta + Integridad OK| H[report]
    G -->|SaturaciÃ³n baja| A
    G -->|Integridad fallida| B
    H --> I[END]
```

### Esfuerzo Estimado: **4 semanas**
- Setup LangGraph: 1 semana
- Migrar lÃ³gica actual: 2 semanas
- Testing y refinamiento: 1 semana

---

## 5. DeepSeek R1 Integration

### Concepto Original
> "Usa modelos chinos para que los bucles infinitos sean baratos."

### Valor para APP_Jupter

| Modelo | Costo/1M tokens | Uso Ideal |
|--------|-----------------|-----------|
| GPT-4o | $5.00 | Decisiones crÃ­ticas (nÃºcleo) |
| **DeepSeek R1** | **$0.55** | CodificaciÃ³n masiva, loops |
| Claude 3.5 | $3.00 | Reasoning complejo |

**Ahorro:** 90% en operaciones repetitivas (codificaciÃ³n de 100 entrevistas)

### ImplementaciÃ³n

```python
# app/llm_router.py

from enum import Enum
from typing import Literal

class LLMTask(Enum):
    CODING_BATCH = "coding_batch"      # Barato, repetitivo
    NUCLEUS_SELECTION = "nucleus"       # CrÃ­tico, razonamiento
    DEDUPLICATION = "dedup"             # Barato, comparaciÃ³n
    REPORT_GENERATION = "report"        # Medio, sÃ­ntesis
    DISCOVERY = "discovery"             # Barato, bÃºsqueda

# Routing table
LLM_ROUTING = {
    LLMTask.CODING_BATCH: "deepseek-chat",
    LLMTask.NUCLEUS_SELECTION: "gpt-4o",
    LLMTask.DEDUPLICATION: "deepseek-chat",
    LLMTask.REPORT_GENERATION: "gpt-4o",
    LLMTask.DISCOVERY: "deepseek-chat",
}

async def call_llm(task: LLMTask, messages: list[dict]) -> str:
    """
    Enruta llamada al modelo Ã³ptimo segÃºn la tarea.
    """
    model = LLM_ROUTING[task]
    
    if model.startswith("deepseek"):
        return await call_deepseek(model, messages)
    elif model.startswith("gpt"):
        return await call_openai(model, messages)
    else:
        return await call_azure(model, messages)

async def call_deepseek(model: str, messages: list[dict]) -> str:
    """Llama a DeepSeek API."""
    client = OpenAI(
        api_key=os.getenv("DEEPSEEK_API_KEY"),
        base_url="https://api.deepseek.com/v1"
    )
    
    response = await client.chat.completions.create(
        model=model,
        messages=messages
    )
    
    return response.choices[0].message.content
```

### .env adicional

```env
# DeepSeek (90% mÃ¡s barato que GPT-4)
DEEPSEEK_API_KEY=sk-xxxxx
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
```

### Esfuerzo Estimado: **1 semana**
- Setup client: 2 dÃ­as
- Router implementation: 2 dÃ­as
- Testing: 3 dÃ­as

---

## 6. Resumen de ImplementaciÃ³n

### Roadmap Propuesto

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ROADMAP FRANKENSTEIN                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  Sprint 29 (2 semanas):                                        â”‚
â”‚  â”œâ”€â”€ DeepSeek R1 integration                                  â”‚
â”‚  â””â”€â”€ Panel de Observabilidad (WebSocket + UI)                 â”‚
â”‚                                                                â”‚
â”‚  Sprint 30 (3 semanas):                                        â”‚
â”‚  â”œâ”€â”€ Matrix Coding UI                                          â”‚
â”‚  â””â”€â”€ Endpoint /api/matrix/fill                                â”‚
â”‚                                                                â”‚
â”‚  Sprint 31 (4 semanas):                                        â”‚
â”‚  â”œâ”€â”€ LangGraph orchestration                                  â”‚
â”‚  â””â”€â”€ MigraciÃ³n de agente autÃ³nomo                             â”‚
â”‚                                                                â”‚
â”‚  Sprint 32 (2 semanas):                                        â”‚
â”‚  â”œâ”€â”€ Refinamiento y testing                                   â”‚
â”‚  â””â”€â”€ DocumentaciÃ³n y demo                                     â”‚
â”‚                                                                â”‚
â”‚  TOTAL: ~11 semanas para transformaciÃ³n completa              â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Presupuesto Estimado (LLM costs)

| Escenario | Modelo Actual (GPT-4o) | Con DeepSeek R1 |
|-----------|------------------------|-----------------|
| 100 entrevistas | $50 | $5.50 |
| 1000 entrevistas | $500 | $55 |
| **Ahorro anual** (10 proyectos/mes) | - | **~$5,000** |

---

## 7. ConclusiÃ³n

### âœ… Alto Valor, Viables

| Feature | Valor | Esfuerzo | ROI |
|---------|-------|----------|-----|
| **DeepSeek R1** | ğŸ’° 90% ahorro | 1 semana | ğŸ”¥ Muy Alto |
| **Panel Observabilidad** | ğŸ” Confianza | 2 semanas | ğŸ”¥ Muy Alto |
| **Matrix UI** | ğŸ“Š 10x velocidad | 3 semanas | ğŸ”¥ Muy Alto |

### ğŸŸ¡ Alto Valor, Mayor InversiÃ³n

| Feature | Valor | Esfuerzo | ROI |
|---------|-------|----------|-----|
| **LangGraph** | ğŸ”§ Robustez | 4 semanas | ğŸŸ¡ Alto |

### âœ… Ya Existente

| Feature | Estado |
|---------|--------|
| **Linkage estricto (Elicit)** | âœ… Implementado |

### RecomendaciÃ³n Final

**Sprint 29 MVP:** DeepSeek + Observabilidad = **3 semanas**

Esto entrega valor inmediato (ahorro de costos + transparencia) mientras se planifica Matrix UI y LangGraph.
