# INFORME COMPLETO DE AN√ÅLISIS DE LOGS
## Sistema de An√°lisis Cualitativo - APP_Jupter

**Fecha de generaci√≥n:** 20 de Diciembre de 2025  
**Per√≠odo analizado:** 11 - 20 de Diciembre de 2025  
**Autor:** An√°lisis automatizado  

---

## üìã RESUMEN EJECUTIVO

El sistema ha procesado un volumen significativo de operaciones durante el per√≠odo analizado, incluyendo:
- **Ingesta de documentos DOCX** con fragmentaci√≥n y embeddings
- **Transcripci√≥n de audio** con diarizaci√≥n de hablantes
- **An√°lisis cualitativo** con LLM (codificaci√≥n abierta, axial, GraphRAG)
- **Almacenamiento multi-base** (Qdrant, Neo4j, PostgreSQL)

### Proyectos Activos Identificados
| Proyecto | Estado | Actividad Principal |
|----------|--------|---------------------|
| nubeweb | Activo | An√°lisis de entrevistas comunitarias |
| baba | Activo | An√°lisis cualitativo |
| prueba-2 | Pruebas | Testing del sistema |
| loadtest | Testing | Pruebas de carga |
| default | Sistema | Configuraci√≥n por defecto |

---

## üî¥ ERRORES CR√çTICOS IDENTIFICADOS

### 1. Errores de API de Azure OpenAI

#### 1.1 Incompatibilidad de par√°metros con modelos de transcripci√≥n
**Frecuencia:** Alta (m√∫ltiples ocurrencias)  
**Fechas afectadas:** 17, 15 de Diciembre

```json
{
  "status": 400,
  "error": "response_format 'verbose_json' is not compatible with model 'gpt-4o-transcribe-diarize'. Use 'json' or 'text' instead."
}
```

**Impacto:** Transcripciones de audio fallaron para 6 chunks de un archivo de 25MB.

**Recomendaci√≥n:** Actualizar `app/transcription.py` para usar `response_format='json'` cuando se utilice el modelo `gpt-4o-transcribe-diarize`.

---

#### 1.2 Falta de chunking_strategy para diarizaci√≥n
**Frecuencia:** Media  
**Fecha:** 15 de Diciembre

```json
{
  "status": 400,
  "error": "chunking_strategy is required for diarization models"
}
```

**Recomendaci√≥n:** Agregar par√°metro `chunking_strategy` en las llamadas al modelo de diarizaci√≥n.

---

#### 1.3 Par√°metro max_tokens no soportado
**Frecuencia:** Alta  
**Fechas:** 15, 16 de Diciembre

```json
{
  "error": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead."
}
```

**M√≥dulos afectados:** 
- `app/graphrag.py`
- `app/analysis.py`

**Recomendaci√≥n:** Migrar de `max_tokens` a `max_completion_tokens` para compatibilidad con modelos o1 y GPT-4o.

---

#### 1.4 Par√°metro temperature no soportado
**Fecha:** 16 de Diciembre

```json
{
  "error": "Unsupported value: 'temperature' does not support 0.3 with this model. Only the default (1) value is supported."
}
```

**M√≥dulo afectado:** `api.analyze_predictions`

---

### 2. Errores de Servidor Azure (5XX)

#### 2.1 Error interno del servidor
**Fecha:** 17 de Diciembre
```json
{
  "status": 500,
  "error": "The server had an error processing your request.",
  "request_id": "68d24949-7164-430e-9859-5cfe11f59c6e"
}
```

**Impacto:** Chunk 7 de 15 fall√≥ durante transcripci√≥n.

---

### 3. Errores de Conectividad

#### 3.1 Timeouts de conexi√≥n HTTP
**Fechas:** 15 de Diciembre (m√∫ltiples)

```
httpx.ConnectTimeout: [WinError 10060] Se produjo un error durante el intento de conexi√≥n
httpx.ReadTimeout: The read operation timed out
```

**Impacto:** Transcripciones de archivos grandes (~20MB) fallaron despu√©s de ~10 minutos.

**Recomendaci√≥n:** 
- Aumentar timeout en cliente httpx
- Implementar reintentos con backoff exponencial

---

#### 3.2 Error de decodificaci√≥n UTF-8
**Fecha:** 13 de Diciembre
**Frecuencia:** ~10 ocurrencias consecutivas

```json
{
  "error": "'utf-8' codec can't decode byte 0xab in position 96: invalid start byte",
  "event": "api.clients.error"
}
```

**M√≥dulo:** `app.api` - Conexi√≥n de clientes

---

### 4. Errores de Neo4j GDS

#### 4.1 Proyecci√≥n de nodos fallida
**Frecuencia:** Alta (m√∫ltiples d√≠as)
**M√≥dulo:** `app/axial.py`

```json
{
  "error": "Invalid node projection, one or more labels not found: 'Categoria, Codigo'",
  "event": "gds.projection_failed_fallback_native"
}
```

**Causa ra√≠z:** Los labels `Categoria` y `Codigo` no existen en la base de datos Neo4j cuando se intenta ejecutar algoritmos GDS.

**Mitigaci√≥n actual:** El sistema hace fallback a algoritmos nativos de Cypher.

---

#### 4.2 Dependencia faltante: scipy
**Fecha:** 12 de Diciembre

```json
{
  "error": "No module named 'scipy'",
  "event": "api.gds.error"
}
```

**Recomendaci√≥n:** Agregar `scipy` a `requirements.txt` y reinstalar dependencias.

---

### 5. Errores de An√°lisis Cualitativo

#### 5.1 Tipos de relaci√≥n inv√°lidos
**Frecuencia:** Muy alta
**Patr√≥n consistente:**

```json
{
  "error": "Tipo de relacion 'relacion' invalido. Debe ser uno de: causa, condicion, consecuencia, partede.",
  "event": "analysis.axial.error"
}
```

**Archivos afectados:**
- Trancripci√≥n_Patricio_Ya√±ez.docx
- Natalia Molina.docx
- test_ingesta.docx

**Causa ra√≠z:** El LLM est√° generando "relacion" como tipo gen√©rico en lugar de los tipos espec√≠ficos permitidos.

**Recomendaci√≥n:** Mejorar el prompt del sistema para an√°lisis axial, enfatizando los tipos v√°lidos.

---

### 6. Errores de Qdrant

#### 6.1 √çndice requerido no encontrado
**Fecha:** 16 de Diciembre

```json
{
  "error": "Index required but not found for \"project\" of one of the following types: [keyword]",
  "event": "api.familiarization.error"
}
```

**Impacto:** Endpoint de familiarization fallando para b√∫squedas por proyecto.

**Recomendaci√≥n:** Crear √≠ndice de tipo keyword para el campo `project` en la colecci√≥n de Qdrant.

---

#### 6.2 Timeout en upsert grande
**Fecha:** 15 de Diciembre

```json
{
  "size": 44,
  "reason": "The write operation timed out",
  "event": "qdrant.upsert.split"
}
```

**Mitigaci√≥n actual:** El sistema divide autom√°ticamente los batches grandes.

---

### 7. Errores de Discovery API

#### 7.1 Validaci√≥n de embeddings fallida
**Frecuencia:** Alta  
**Fechas:** 14, 15 de Diciembre

```json
{
  "error": "8 validation errors for DiscoverRequest - context.0.positive.list[float].0: Input should be a valid number"
}
```

**Causa ra√≠z:** Los embeddings se pasan como lista de listas en lugar de lista plana.

**M√≥dulo afectado:** `app/queries.py`

---

## ‚ö†Ô∏è WARNINGS IMPORTANTES

### 1. Neo4j - Elementos no encontrados

| Tipo | Elemento | Frecuencia |
|------|----------|------------|
| Label | `Categoria` | Alta |
| Label | `Codigo` | Alta |
| Label | `User`, `Question`, `Answer` | Media |
| RelType | `REL` | Alta |
| RelType | `TIENE_CODIGO` | Alta |
| Property | `score_centralidad` | Media |
| Property | `community_id` | Media |
| Property | `fragmento_id` | Media |
| Property | `evidencia` | Media |

**Interpretaci√≥n:** El esquema de Neo4j no coincide con las consultas esperadas. Posiblemente la base de datos fue reiniciada o el esquema cambi√≥.

---

### 2. Fragmentos con problemas de calidad

**Patr√≥n detectado:** `filler_repetition`  
**Descripci√≥n:** Fragmentos con muletillas o repeticiones excesivas

**Archivos m√°s afectados:**
| Archivo | Fragmentos Flagged |
|---------|-------------------|
| Guillermo Orestes.docx | 13 |
| Pablo_Fabrega.docx | 19 |
| Trancripci√≥n_Camilo_Colegio_Cayenel.docx | 12 |

---

## ‚úÖ OPERACIONES EXITOSAS

### 1. Ingestas Completadas

| Fecha | Proyecto | Archivo | Fragmentos | Tokens Procesados |
|-------|----------|---------|------------|-------------------|
| 12/12 | nubeweb | Guillermo Orestes.docx | 44 | 4,061 |
| 12/12 | nubeweb | Natalia Molina.docx | 24 | 2,782 |
| 12/12 | prueba-2 | Trancripci√≥n_Patricio_Ya√±ez.docx | 23 | 2,464 |
| 15/12 | nubeweb | Claudia_Cesfam.docx | 21 | 1,263 |
| 15/12 | nubeweb | Pablo_Fabrega.docx | 34 | 5,358 |
| 15/12 | nubeweb | Trancripci√≥n_Camilo_Colegio_Cayenel.docx | 29 | 3,582 |
| 15/12 | nubeweb | Trancripci√≥n_Elba.docx | 25 | 3,459 |
| 16/12 | nubeweb | EntrevistaJardinInfantil_UVJuanPabloII.docx | 4 | 2,047 |

---

### 2. Transcripciones de Audio Exitosas

| Fecha | Archivo Original | Duraci√≥n | Chunks | Speakers |
|-------|-----------------|----------|--------|----------|
| 17/12 | Audio 64MB | 70min | 15 | 1 |
| 17/12 | Audio 65MB | 94min | 19 | 1 |

**Nota:** Optimizaci√≥n de audio efectiva (reducci√≥n ~50% tama√±o).

---

### 3. An√°lisis Axial Persistidos

**Proyecto baba (14/12):**
- 10 relaciones procesadas
- 100% linkage rate
- Categor√≠as: `contexto_hist√≥rico_y_social`, `labor_formativa_y_valores`, `barreras_y_conflictos`

**Proyecto nubeweb (15/12):**
- Categor√≠as: `deporte_como_prevencion_e_inclusion_social`, `barreras_institucionales_y_estructurales`
- Tipos de relaci√≥n: `partede`, `causa`

---

### 4. Consultas GraphRAG Completadas

| Fecha | Proyecto | Query | Nodos | Respuesta (chars) |
|-------|----------|-------|-------|-------------------|
| 15/12 | nubeweb | "que teor√≠a emerge de la codificaci√≥n" | 0 | 2,741 |
| 15/12 | default | "que significado le asignan los entrevistados" | 0 | 3,303 |
| 16/12 | nubeweb | "relaci√≥n inundaci√≥n calles" | 0 | 2,654 |
| 16/12 | nubeweb | "relaci√≥n desarrollo urbano problemas" | 0 | 2,234 |

**Observaci√≥n:** Todas las consultas retornan 0 nodos del grafo, indicando que el contexto viene principalmente de la b√∫squeda vectorial.

---

### 5. Link Prediction Funcionando

| Fecha | Algoritmo | Candidatos | Retornados |
|-------|-----------|------------|------------|
| 14/12 | preferential_attachment | 412 | 10 |
| 16/12 | preferential_attachment | 1,163 | 10 |
| 16/12 | preferential_attachment | 3,505 | 10 |

---

### 6. Semantic Discovery (Fallback)

**Estado:** Operativo con fallback a weighted vector search

```json
{
  "reason": "weighted vector search",
  "event": "discover.using_fallback",
  "results": 10
}
```

---

## üìä M√âTRICAS DE USO

### Reinicios del Sistema
| Fecha | Cantidad de Reinicios |
|-------|----------------------|
| 11/12 | 35+ |
| 12/12 | 45+ |
| 13/12 | 30+ |
| 14/12 | 25+ |
| 15/12 | 40+ |
| 16/12 | 35+ |
| 17/12 | 5+ |

**Observaci√≥n:** Alta frecuencia de reinicios indica desarrollo activo o inestabilidad.

---

### Distribuci√≥n de Niveles de Log

| Nivel | Porcentaje Aproximado |
|-------|----------------------|
| info | 75% |
| warning | 15% |
| error | 10% |

---

## üîß RECOMENDACIONES DE ACCI√ìN

### Alta Prioridad

1. **Actualizar par√°metros de API Azure:**
   - Cambiar `max_tokens` ‚Üí `max_completion_tokens`
   - Cambiar `response_format='verbose_json'` ‚Üí `response_format='json'`
   - Agregar `chunking_strategy` para diarizaci√≥n
   - Remover o ajustar `temperature` para modelos que no lo soportan

2. **Crear √≠ndices en Qdrant:**
   ```python
   client.create_payload_index(
       collection_name="fragmentos",
       field_name="project",
       field_schema=models.PayloadSchemaType.KEYWORD
   )
   ```

3. **Instalar dependencia faltante:**
   ```bash
   pip install scipy
   ```

4. **Mejorar prompt de an√°lisis axial:**
   - Enfatizar tipos v√°lidos: `causa`, `condicion`, `consecuencia`, `partede`
   - Agregar ejemplos en el prompt

### Media Prioridad

5. **Aumentar timeouts HTTP para transcripciones largas**

6. **Implementar health check de Neo4j** antes de ejecutar GDS

7. **Corregir formato de embeddings** en Discovery API

### Baja Prioridad

8. **Optimizar frecuencia de logging_configured** (demasiados eventos repetidos)

9. **Agregar m√©tricas de monitoreo** (Prometheus/Grafana)

---

## üìÅ ARCHIVOS DE LOG ANALIZADOS

| Archivo | L√≠neas | Per√≠odo |
|---------|--------|---------|
| app.jsonl.2025-12-11 | ~100 | 01:26 - 02:54 UTC |
| app.jsonl.2025-12-12 | 209 | 03:02 - 14:24 UTC |
| app.jsonl.2025-12-13 | 245 | 16:53 - 02:58 UTC+1 |
| app.jsonl.2025-12-14 | 200 | 03:00 - 04:27 UTC |
| app.jsonl.2025-12-15 | 476 | 03:02 - 18:50 UTC |
| app.jsonl.2025-12-16 | 338 | 03:23 - 23:48 UTC |
| app.jsonl.2025-12-17 | 344 | 17:03 - 18:26 UTC |

---

## üîç PATRONES IDENTIFICADOS

### 1. Flujo de trabajo t√≠pico
```
logging_configured ‚Üí project.created ‚Üí ingest.file.start ‚Üí 
qdrant.upsert.success ‚Üí ingest.batch ‚Üí ingest.file.end ‚Üí 
analyze.queued ‚Üí analysis.persist.linkage_metrics ‚Üí 
analysis.axial.persisted ‚Üí analyze.persisted_manual
```

### 2. Flujo de transcripci√≥n
```
audio.optimize.success ‚Üí transcribe_chunked.start ‚Üí 
split_audio.start ‚Üí split_audio.complete ‚Üí 
transcribe_chunked.chunk (√óN) ‚Üí transcription.complete ‚Üí 
transcribe_chunked.complete ‚Üí api.transcribe.saved
```

### 3. Flujo de consulta GraphRAG
```
api.graphrag.start ‚Üí graphrag.query_start ‚Üí 
graphrag.subgraph_extracted ‚Üí graphrag.query_complete ‚Üí 
api.graphrag.complete ‚Üí report.saved
```

---

## üìà CONCLUSIONES

1. **El sistema est√° operativo** pero con varios errores de compatibilidad con APIs de Azure OpenAI.

2. **Neo4j GDS tiene problemas de esquema** - los algoritmos hacen fallback a Cypher nativo.

3. **La ingesta funciona correctamente** con buen rendimiento en fragmentaci√≥n y embeddings.

4. **Las transcripciones de audio** funcionan para archivos peque√±os pero fallan en archivos grandes.

5. **El an√°lisis axial** requiere ajustes en el prompt para generar tipos de relaci√≥n v√°lidos.

6. **La Discovery API** necesita correcci√≥n en el formato de embeddings.

---

*Informe generado autom√°ticamente - Sistema APP_Jupter*
