# ğŸ” AuditorÃ­a de Calidad: Discovery Runner & Post-Run

ImplementaciÃ³n evaluada tras una ejecuciÃ³n del Runner Discovery para el proyecto `jd-009`.

Esta auditorÃ­a se enfoca en reducir alucinaciones (claims no sustentados) y en alinear la salida del Runner con el objetivo de negocio:

> Convertir entrevistas y documentos en **insights accionables y auditables**, con **trazabilidad** desde el hallazgo hasta los fragmentos de evidencia.

## 1) Hechos verificables (anclados a cÃ³digo)

### 1.1 Muestreo de evidencia para el post-run âœ…
- El runner mantiene una muestra de fragmentos Ãºnicos â€œmejores por scoreâ€ acumulados a travÃ©s de iteraciones (no solo la Ãºltima iteraciÃ³n).
- Evidencia: `best_fragments` y `sample_fragments` en `app/discovery_runner.py`.

### 1.2 Resiliencia mÃ­nima ante fallos de infraestructura âœ…
- Embeddings: retry con backoff implementado localmente en el runner (no usa Tenacity aquÃ­).
- Qdrant search: retry con backoff implementado en el runner.
- Evidencia: `_embed_query_with_retry()` y `_search_qdrant_with_retry()` en `app/discovery_runner.py`.

### 1.3 Post-run: sÃ­ntesis + artefactos âœ…
- El post-run genera un JSON estructurado con: memo, cÃ³digos sugeridos, decisiones y prÃ³ximos pasos; luego escribe un reporte Markdown.
- Evidencia: `_analyze_fragments_with_llm()` y `_write_runner_report()` en `backend/routers/agent.py`.

## 2) MÃ©trica â€œLanding rateâ€: definiciÃ³n operativa (antiâ€‘alucinaciÃ³n)

**DefiniciÃ³n real (actual):**
- El â€œlanding rateâ€ se calcula como la proporciÃ³n de fragmentos recuperados por Discovery que ya aparecen codificados en `analisis_codigos_abiertos` para el proyecto.
- Nota: `analisis_codigos_abiertos` contiene codificaciÃ³n abierta ya persistida (no necesariamente â€œaxial/definitivaâ€).

**Salida y diagnÃ³stico:**
- `landing_rate` se entrega como porcentaje (0â€“100).
- `reason` puede ser:
	- `no_fragments`: no hubo fragmentos.
	- `no_definitive_codes`: el proyecto no tiene filas en `analisis_codigos_abiertos` (por tanto, el landing rate tiende a 0 aunque haya buenos hallazgos).
	- `no_overlap_with_definitive_codes`: hay codificaciÃ³n previa, pero no hubo overlap.
	- `ok`: hay overlap.

Evidencia: `calculate_landing_rate()` en `app/postgres_block.py`.

## 3) Controles antiâ€‘alucinaciÃ³n (estado actual)

### 3.1 Controles ya presentes âœ…
- El LLM estÃ¡ forzado a responder â€œsolo JSONâ€ (reduce texto libre y deriva de formato).
- El informe incluye `fragmento_id` y fragmentos textuales (permite verificaciÃ³n humana).

### 3.2 Brechas que aÃºn permiten alucinaciones (y por quÃ© importan)
- La sÃ­ntesis/cÃ³digos no incluyen trazabilidad explÃ­cita â€œcÃ³digo â†’ fragmentos que lo sustentanâ€.
- El postâ€‘run usa una muestra (subset) de fragmentos (por diseÃ±o), por lo que afirmaciones del tipo â€œausencia de Xâ€ pueden ser artefacto de muestreo.
- No hay score/umbral por cÃ³digo sugerido (todas las sugerencias se ven â€œplanasâ€).

## 4) ConclusiÃ³n (ajustada a evidencia)

- El Runner + postâ€‘run estÃ¡ operativo y produce artefactos Ãºtiles para avanzar (reporte + sugerencias), con trazabilidad bÃ¡sica vÃ­a `fragmento_id`.
- No se debe presentar como â€œauditable/enterprise-readyâ€ sin explicitar limitaciones y sin aÃ±adir trazabilidad cÃ³digoâ†’evidencia y controles de calidad reproducibles.

## 5) Recomendaciones (para cumplir el objetivo 2025)

1) En los reportes: etiquetar explÃ­citamente la sÃ­ntesis como **hipÃ³tesis** basada en una muestra y exigir validaciÃ³n en bandeja.
2) AÃ±adir â€œevidencia mÃ­nima por cÃ³digoâ€: 1â€“3 `fragmento_id` por cÃ³digo sugerido.
3) AÃ±adir metadatos de ejecuciÃ³n al reporte: `top_k`, `score_threshold`, `max_interviews`, iters, y `reason/project_open_code_rows` para interpretar landing rate.

*Actualizado para enfoque antiâ€‘alucinaciones - Enero 2026*
