{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19cd699",
   "metadata": {},
   "source": [
    "\n",
    "# üìì Tuber√≠a de Ingesta y An√°lisis Cualitativo de Entrevistas (DOCX ‚Üí Embeddings ‚Üí Qdrant/Neo4j/PostgreSQL)\n",
    "\n",
    "**Fecha de generaci√≥n:** 2025-10-29T22:13:14Z\n",
    "\n",
    "Este cuaderno implementa una **tuber√≠a reproducible** para:\n",
    "\n",
    "- **Extraer** texto desde entrevistas en `.docx` (p√°rrafos/fragmentos).\n",
    "- **Generar embeddings** con *Azure OpenAI* usando **deployments** (no modelos base).\n",
    "- **Cargar y sincronizar** cada fragmento en tres almacenes complementarios:\n",
    "  - **Qdrant (vector DB)** para b√∫squeda sem√°ntica/similaridad.\n",
    "  - **Neo4j (grafo)** para modelar relaciones `(:Entrevista)-[:TIENE_FRAGMENTO]->(:Fragmento)`.\n",
    "  - **PostgreSQL (relacional)** para consulta estructurada, auditor√≠as y reporting (`embedding DOUBLE PRECISION[]`).\n",
    "\n",
    "Adem√°s, incluye **celdas de apoyo para el an√°lisis cualitativo** (Etapas 0‚Äì9) con prompts estandarizados para:\n",
    "- Resumen/descripci√≥n inicial.\n",
    "- Codificaci√≥n abierta y axial (tablas/matrices).\n",
    "- Codificaci√≥n selectiva e integraci√≥n narrativa.\n",
    "- An√°lisis tem√°tico transversal y **modelo explicativo** (diagrama ASCII).\n",
    "- Opciones para **persistir matrices** en PostgreSQL.\n",
    "\n",
    "> ‚ö†Ô∏è **Seguridad**: No pegues tus claves directamente en el cuaderno. Usa un archivo `.env` local, variables de entorno o Azure Entra ID. Si previamente expusiste claves en notebooks, **rota** esas credenciales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af01b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (Opcional) Instalar dependencias si hace falta (comenta si ya est√°n instaladas)\n",
    "# Nota: Ejecuta en tu entorno con internet.\n",
    "# %pip install -U python-dotenv python-docx qdrant-client neo4j psycopg2-binary openai azure-identity azure-storage-blob tqdm tenacity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0bb99",
   "metadata": {},
   "source": [
    "\n",
    "## 0. Configuraci√≥n y credenciales (.env)\n",
    "\n",
    "Crea un archivo `.env` en la carpeta del cuaderno con variables como:\n",
    "\n",
    "```env\n",
    "# Azure OpenAI\n",
    "AZURE_OPENAI_ENDPOINT=https://<tu-recurso>.openai.azure.com\n",
    "AZURE_OPENAI_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "AZURE_OPENAI_API_VERSION=2024-08-01-preview\n",
    "AZURE_OPENAI_DEPLOYMENT_EMBED=text-embedding-3-large\n",
    "AZURE_OPENAI_DEPLOYMENT_CHAT=gpt-4o-mini\n",
    "\n",
    "# Qdrant\n",
    "QDRANT_URI=https://<cluster-id>.<region>.cloud.qdrant.io\n",
    "QDRANT_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "\n",
    "# Neo4j\n",
    "NEO4J_URI=neo4j+s://<id>.databases.neo4j.io\n",
    "NEO4J_USERNAME=neo4j\n",
    "NEO4J_PASSWORD=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "NEO4J_DATABASE=neo4j\n",
    "\n",
    "# PostgreSQL\n",
    "PGHOST=localhost\n",
    "PGPORT=5432\n",
    "PGUSER=postgres\n",
    "PGPASSWORD=<tu_password>\n",
    "PGDATABASE=system_inv_sociocultural_v1\n",
    "\n",
    "# Colecci√≥n Qdrant y dimensiones\n",
    "QDRANT_COLLECTION=entrevistas\n",
    "EMBED_DIMS=3072  # text-embedding-3-large\n",
    "```\n",
    "\n",
    "> **Importante**: El endpoint de Azure OpenAI **debe** terminar en `.openai.azure.com`. Un endpoint como `...cognitive.microsoft.com` _no_ es v√°lido para Azure OpenAI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7753108",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crea un .env de ejemplo (no contiene secretos reales)\n",
    "from pathlib import Path\n",
    "\n",
    "env_example = Path(\"env.example\")\n",
    "if not env_example.exists():\n",
    "    env_example.write_text(\n",
    "        \"AZURE_OPENAI_ENDPOINT=https://<tu-recurso>.openai.azure.com\\n\"\n",
    "        \"AZURE_OPENAI_API_KEY=REEMPLAZAR\\n\"\n",
    "        \"AZURE_OPENAI_API_VERSION=2024-08-01-preview\\n\"\n",
    "        \"AZURE_OPENAI_DEPLOYMENT_EMBED=text-embedding-3-large\\n\"\n",
    "        \"AZURE_OPENAI_DEPLOYMENT_CHAT=gpt-4o-mini\\n\"\n",
    "        \"QDRANT_URI=https://<cluster-id>.<region>.cloud.qdrant.io\\n\"\n",
    "        \"QDRANT_API_KEY=REEMPLAZAR\\n\"\n",
    "        \"NEO4J_URI=neo4j+s://<id>.databases.neo4j.io\\n\"\n",
    "        \"NEO4J_USERNAME=neo4j\\n\"\n",
    "        \"NEO4J_PASSWORD=REEMPLAZAR\\n\"\n",
    "        \"NEO4J_DATABASE=neo4j\\n\"\n",
    "        \"PGHOST=localhost\\n\"\n",
    "        \"PGPORT=5432\\n\"\n",
    "        \"PGUSER=postgres\\n\"\n",
    "        \"PGPASSWORD=REEMPLAZAR\\n\"\n",
    "        \"PGDATABASE=system_inv_sociocultural_v1\\n\"\n",
    "        \"QDRANT_COLLECTION=entrevistas\\n\"\n",
    "        \"EMBED_DIMS=3072\\n\"\n",
    "    )\n",
    "env_example.resolve()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86ef45",
   "metadata": {},
   "source": [
    "## 1. Cargar configuraci√≥n y preparar clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, uuid, hashlib, time, json, math, re\n",
    "from typing import List, Dict, Tuple\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(usecwd=True), override=True)\n",
    "\n",
    "def mask(v: str, a: int = 4) -> str:\n",
    "    if not v: return \"****\"\n",
    "    return v[:a] + \"‚Ä¶\" + v[-a:] if len(v) > (2*a) else \"****\"\n",
    "\n",
    "# --- Azure OpenAI ---\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\") or \"\"\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\") or \"\"\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-08-01-preview\")\n",
    "DEP_EMBED = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_EMBED\", \"text-embedding-3-large\")\n",
    "DEP_CHAT  = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_CHAT\", \"gpt-4o-mini\")\n",
    "\n",
    "if \".openai.azure.com\" not in AZURE_OPENAI_ENDPOINT:\n",
    "    print(\"‚ö†Ô∏è  AVISO: AZURE_OPENAI_ENDPOINT no parece v√°lido para Azure OpenAI:\", AZURE_OPENAI_ENDPOINT)\n",
    "\n",
    "if AZURE_OPENAI_API_KEY.strip():\n",
    "    aoai = AzureOpenAI(azure_endpoint=AZURE_OPENAI_ENDPOINT, api_key=AZURE_OPENAI_API_KEY, api_version=AZURE_OPENAI_API_VERSION)\n",
    "    print(\"Azure OpenAI (API key) listo ‚Üí\", AZURE_OPENAI_ENDPOINT)\n",
    "else:\n",
    "    scope = \"https://cognitiveservices.azure.com/.default\"\n",
    "    credential = DefaultAzureCredential()\n",
    "    token_provider = get_bearer_token_provider(credential, scope)\n",
    "    aoai = AzureOpenAI(azure_endpoint=AZURE_OPENAI_ENDPOINT, azure_ad_token_provider=token_provider, api_version=AZURE_OPENAI_API_VERSION)\n",
    "    print(\"Azure OpenAI (Entra ID) listo ‚Üí\", AZURE_OPENAI_ENDPOINT)\n",
    "\n",
    "# --- Qdrant ---\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "\n",
    "QDRANT_URI = os.getenv(\"QDRANT_URI\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "QDRANT_COLLECTION = os.getenv(\"QDRANT_COLLECTION\", \"entrevistas\")\n",
    "\n",
    "qdrant = QdrantClient(url=QDRANT_URI, api_key=QDRANT_API_KEY)\n",
    "print(\"Qdrant:\", QDRANT_URI)\n",
    "\n",
    "# --- Neo4j ---\n",
    "from neo4j import GraphDatabase\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\"); NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\"); NEO4J_DATABASE = os.getenv(\"NEO4J_DATABASE\",\"neo4j\")\n",
    "\n",
    "neo = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "print(\"Neo4j:\", NEO4J_URI)\n",
    "\n",
    "# --- PostgreSQL ---\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "PGHOST=os.getenv(\"PGHOST\",\"localhost\"); PGPORT=int(os.getenv(\"PGPORT\",\"5432\"))\n",
    "PGUSER=os.getenv(\"PGUSER\",\"postgres\"); PGPASSWORD=os.getenv(\"PGPASSWORD\",\"\"); PGDATABASE=os.getenv(\"PGDATABASE\",\"postgres\")\n",
    "\n",
    "pg = psycopg2.connect(host=PGHOST, port=PGPORT, dbname=PGDATABASE, user=PGUSER, password=PGPASSWORD)\n",
    "pg.set_client_encoding(\"UTF8\")\n",
    "pg_cur = pg.cursor()\n",
    "print(f\"PostgreSQL: {PGUSER}@{PGHOST}:{PGPORT}/{PGDATABASE}\")\n",
    "\n",
    "def get_embed_dim_fallback() -> int:\n",
    "    # Intenta deducir dims del deployment de embeddings con una llamada m√≠nima\n",
    "    try:\n",
    "        vec = aoai.embeddings.create(model=DEP_EMBED, input=\"ping\").data[0].embedding\n",
    "        return len(vec)\n",
    "    except Exception as e:\n",
    "        print(\"No se pudo inferir dimensi√≥n autom√°ticamente:\", e)\n",
    "        return int(os.getenv(\"EMBED_DIMS\", \"3072\"))  # fallback conocido para text-embedding-3-large\n",
    "\n",
    "EMBED_DIMS = int(os.getenv(\"EMBED_DIMS\", \"0\")) or get_embed_dim_fallback()\n",
    "print(\"Dimensiones de embedding:\", EMBED_DIMS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451f845f",
   "metadata": {},
   "source": [
    "## 2. Health checks y preparaci√≥n de esquemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f809373",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Qdrant: asegurar colecci√≥n con dimensiones correctas\n",
    "def ensure_qdrant_collection(client: QdrantClient, name: str, dims: int, distance=Distance.COSINE) -> None:\n",
    "    if client.collection_exists(name):\n",
    "        info = client.get_collection(name)\n",
    "        current = info.config.params.vectors.size\n",
    "        if current != dims:\n",
    "            raise RuntimeError(f\"La colecci√≥n '{name}' existe con size={current} y se requiere size={dims}. \"\n",
    "                               \"Elimina/renombra y vuelve a crearla con el tama√±o correcto.\")\n",
    "        return\n",
    "    client.create_collection(name, vectors_config=VectorParams(size=dims, distance=distance))\n",
    "\n",
    "ensure_qdrant_collection(qdrant, QDRANT_COLLECTION, EMBED_DIMS)\n",
    "print(f\"Qdrant OK ‚Üí colecci√≥n '{QDRANT_COLLECTION}' lista.\")\n",
    "\n",
    "# Neo4j: ping + constraints\n",
    "with neo.session(database=NEO4J_DATABASE) as s:\n",
    "    pong = s.run(\"RETURN 'pong' AS ping\").single()[\"ping\"]\n",
    "    print(\"Neo4j ping:\", pong)\n",
    "    s.run(\"CREATE CONSTRAINT ent_nombre IF NOT EXISTS FOR (e:Entrevista) REQUIRE e.nombre IS UNIQUE\")\n",
    "    s.run(\"CREATE CONSTRAINT frag_id IF NOT EXISTS FOR (f:Fragmento) REQUIRE f.id IS UNIQUE\")\n",
    "    print(\"Constraints verificados.\")\n",
    "\n",
    "# PostgreSQL: crear tabla (embedding DOUBLE PRECISION[]) + √≠ndices\n",
    "pg_cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS entrevista_fragmentos (\n",
    "  id TEXT PRIMARY KEY,\n",
    "  archivo TEXT NOT NULL,\n",
    "  par_idx INT NOT NULL,\n",
    "  fragmento TEXT NOT NULL,\n",
    "  embedding DOUBLE PRECISION[] NOT NULL,\n",
    "  char_len INT NOT NULL,\n",
    "  sha256 TEXT NOT NULL,\n",
    "  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n",
    "  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n",
    ");\n",
    "CREATE INDEX IF NOT EXISTS ix_ef_archivo ON entrevista_fragmentos(archivo);\n",
    "CREATE INDEX IF NOT EXISTS ix_ef_charlen ON entrevista_fragmentos(char_len);\n",
    "\"\"\")\n",
    "pg.commit()\n",
    "print(\"PostgreSQL OK ‚Üí tabla 'entrevista_fragmentos' lista.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bc3f4e",
   "metadata": {},
   "source": [
    "## 3. Utilidades de lectura y segmentaci√≥n (.docx ‚Üí fragmentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190ddf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from docx import Document\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = s.replace('\\u00A0', ' ')  # NBSP ‚Üí espacio\n",
    "    s = re.sub(r'[ \\t]+', ' ', s)\n",
    "    s = re.sub(r'\\s+\\n', '\\n', s)\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "def read_paragraphs_from_docx(path: str) -> List[str]:\n",
    "    try:\n",
    "        d = Document(path)\n",
    "        paras = [normalize_text(p.text) for p in d.paragraphs if p.text and p.text.strip()]\n",
    "        return [p for p in paras if p]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error leyendo '{path}':\", e)\n",
    "        return []\n",
    "\n",
    "def coalesce_small(paragraphs: List[str], min_chars: int = 200, max_chars: int = 1200) -> List[str]:\n",
    "    \"\"\"\n",
    "    Une p√°rrafos demasiado cortos para evitar fragmentos pobres, sin pasar el m√°ximo.\n",
    "    Heur√≠stica simple por longitud (chars).\n",
    "    \"\"\"\n",
    "    acc, buf = [], \"\"\n",
    "    for p in paragraphs:\n",
    "        if not buf:\n",
    "            buf = p\n",
    "            continue\n",
    "        if len(buf) < min_chars and len(buf) + 1 + len(p) <= max_chars:\n",
    "            buf = buf + \" \" + p\n",
    "        else:\n",
    "            acc.append(buf)\n",
    "            buf = p\n",
    "    if buf:\n",
    "        acc.append(buf)\n",
    "    return acc\n",
    "\n",
    "def make_fragment_id(file_name: str, idx: int) -> str:\n",
    "    return str(uuid.uuid5(uuid.NAMESPACE_URL, f\"{file_name}|{idx}\"))\n",
    "\n",
    "def batched(seq, size: int):\n",
    "    buf = []\n",
    "    for x in seq:\n",
    "        buf.append(x)\n",
    "        if len(buf) >= size:\n",
    "            yield buf\n",
    "            buf = []\n",
    "    if buf:\n",
    "        yield buf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c169b",
   "metadata": {},
   "source": [
    "## 4. Embeddings en batch (Azure OpenAI Deployments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c6823",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embed_batch(texts: List[str]) -> List[List[float]]:\n",
    "    # Mantiene orden de entrada\n",
    "    resp = aoai.embeddings.create(model=DEP_EMBED, input=texts)\n",
    "    data_sorted = sorted(resp.data, key=lambda d: d.index)\n",
    "    vecs = [d.embedding for d in data_sorted]\n",
    "    # Sanidad r√°pida\n",
    "    if any(len(v) != EMBED_DIMS for v in vecs):\n",
    "        raise RuntimeError(\"Dimensiones de los embeddings no coinciden con EMBED_DIMS.\")\n",
    "    return vecs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf751a8",
   "metadata": {},
   "source": [
    "## 5. Upsert en Qdrant / MERGE en Neo4j / INSERT en PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qdrant_upsert_points(client: QdrantClient, collection: str, ids: List[str],\n",
    "                         files_and_frags: List[Tuple[str, int, str]],\n",
    "                         vectors: List[List[float]]) -> None:\n",
    "    pts = []\n",
    "    for _id, (archivo, par_idx, frag), vec in zip(ids, files_and_frags, vectors):\n",
    "        pts.append(PointStruct(\n",
    "            id=str(_id),\n",
    "            vector=vec,\n",
    "            payload={\n",
    "                \"archivo\": archivo,\n",
    "                \"par_idx\": par_idx,\n",
    "                \"fragmento\": frag,\n",
    "                \"char_len\": len(frag)\n",
    "            }\n",
    "        ))\n",
    "    client.upsert(collection_name=collection, points=pts)\n",
    "\n",
    "def neo4j_merge(driver, database: str, rows: List[Dict[str, str]]) -> None:\n",
    "    cypher = \"\"\"\n",
    "    UNWIND $rows AS r\n",
    "    MERGE (e:Entrevista {nombre: r.archivo})\n",
    "    MERGE (f:Fragmento {id: r.id})\n",
    "      ON CREATE SET f.texto = r.fragmento, f.par_idx = r.par_idx, f.char_len = r.char_len\n",
    "      ON MATCH  SET f.texto = coalesce(r.fragmento, f.texto), f.char_len = r.char_len\n",
    "    MERGE (e)-[:TIENE_FRAGMENTO]->(f)\n",
    "    \"\"\"\n",
    "    with driver.session(database=database) as s:\n",
    "        s.run(cypher, rows=rows)\n",
    "\n",
    "def pg_insert(pg_cur, rows: List[Tuple[str, str, int, str, list, int, str]]):\n",
    "    sql = \"\"\"\n",
    "    INSERT INTO entrevista_fragmentos (id, archivo, par_idx, fragmento, embedding, char_len, sha256)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (id) DO UPDATE SET\n",
    "      fragmento = EXCLUDED.fragmento,\n",
    "      embedding = EXCLUDED.embedding,\n",
    "      char_len  = EXCLUDED.char_len,\n",
    "      sha256    = EXCLUDED.sha256,\n",
    "      updated_at = NOW();\n",
    "    \"\"\"\n",
    "    execute_values(pg_cur, sql, rows, page_size=200)\n",
    "\n",
    "def sha256_text(s: str) -> str:\n",
    "    return hashlib.sha256(s.encode('utf-8')).hexdigest()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3449d271",
   "metadata": {},
   "source": [
    "## 6. Orquestador de ingesta (DOCX ‚Üí fragmentos ‚Üí embeddings ‚Üí 3 almacenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11573e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def ingest_files(file_paths: List[str], batch_size: int = 64, coalesce_min_chars: int = 200, coalesce_max_chars: int = 1200):\n",
    "    ensure_qdrant_collection(qdrant, QDRANT_COLLECTION, EMBED_DIMS)\n",
    "    total = 0\n",
    "    for path in file_paths:\n",
    "        archivo = os.path.basename(path)\n",
    "        paras = read_paragraphs_from_docx(path)\n",
    "        if not paras:\n",
    "            print(f\"‚ö†Ô∏è  {archivo}: sin contenido utilizable.\")\n",
    "            continue\n",
    "\n",
    "        frags = coalesce_small(paras, min_chars=coalesce_min_chars, max_chars=coalesce_max_chars)\n",
    "        ids = [make_fragment_id(archivo, i) for i in range(len(frags))]\n",
    "        file_triplets = [(archivo, i, frag) for i, frag in enumerate(frags)]\n",
    "        print(f\"üìÑ {archivo} ‚Üí {len(frags)} fragmentos (fuente: {len(paras)} p√°rrafos)\")\n",
    "\n",
    "        # embeddings en batch\n",
    "        vectors = []\n",
    "        for chunk in tqdm(list(batched(frags, batch_size)), desc=f\"Embeddings {archivo}\"):\n",
    "            vectors.extend(embed_batch(chunk))\n",
    "\n",
    "        # Qdrant\n",
    "        qdrant_upsert_points(qdrant, QDRANT_COLLECTION, ids, file_triplets, vectors)\n",
    "\n",
    "        # Neo4j\n",
    "        neo_rows = [{\n",
    "            \"id\": _id,\n",
    "            \"archivo\": archivo,\n",
    "            \"fragmento\": frag,\n",
    "            \"par_idx\": idx,\n",
    "            \"char_len\": len(frag)\n",
    "        } for _id, (archivo, idx, frag) in zip(ids, file_triplets)]\n",
    "        neo4j_merge(neo, NEO4J_DATABASE, neo_rows)\n",
    "\n",
    "        # Postgres\n",
    "        pg_rows = [(_id, archivo, idx, frag, vec, len(frag), sha256_text(frag))\n",
    "                   for _id, (archivo, idx, frag), vec in zip(ids, file_triplets, vectors)]\n",
    "        pg_insert(pg_cur, pg_rows); pg.commit()\n",
    "\n",
    "        total += len(frags)\n",
    "        print(f\"‚úîÔ∏è  {archivo}: {len(frags)} fragmentos cargados.\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Ingesta finalizada. Total fragmentos: {total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a60c621",
   "metadata": {},
   "source": [
    "## 7. Lista de entrevistas (.docx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f59cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reemplaza con tus rutas locales en Windows/Linux/Mac\n",
    "interview_files = [\n",
    "    r\"C:\\ruta\\a\\tu\\Entrevistas\\Entre1.docx\",\n",
    "    r\"C:\\ruta\\a\\tu\\Entrevistas\\Entre2.docx\",\n",
    "    # ...\n",
    "]\n",
    "\n",
    "# (Opcional) Utilidad que sugiere 'Transcripci√≥n' si hay error tipogr√°fico com√∫n\n",
    "def exists_or_fix(path: str):\n",
    "    import os\n",
    "    if os.path.exists(path): return (\"OK\", path)\n",
    "    alt = path.replace(\"Trancripci√≥n\", \"Transcripci√≥n\")\n",
    "    if alt != path and os.path.exists(alt): return (\"SUGERIDO\", alt)\n",
    "    return (\"NO_ENCONTRADO\", path)\n",
    "\n",
    "files_ok = []\n",
    "for p in interview_files:\n",
    "    status, use = exists_or_fix(p)\n",
    "    print(f\"{status:12} ‚Äî {use}\")\n",
    "    if status != \"NO_ENCONTRADO\": files_ok.append(use)\n",
    "\n",
    "print(f\"‚û°Ô∏è  Se procesar√°n {len(files_ok)} archivos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3551952d",
   "metadata": {},
   "source": [
    "## 8. Ejecutar ingesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c241c27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ejecuta la ingesta (descomenta para correr)\n",
    "# ingest_files(files_ok, batch_size=64, coalesce_min_chars=200, coalesce_max_chars=1200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86161c34",
   "metadata": {},
   "source": [
    "## 9. Pruebas de consulta (Qdrant / Neo4j / Postgres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f3915",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def semantic_search(query: str, top_k: int = 5):\n",
    "    qvec = aoai.embeddings.create(model=DEP_EMBED, input=query).data[0].embedding\n",
    "    res = qdrant.query_points(collection_name=QDRANT_COLLECTION, query=qvec, limit=top_k, with_payload=True)\n",
    "    print(f\"Consulta: {query}\\nTop-{top_k} resultados:\\n\")\n",
    "    for p in res.points:\n",
    "        pl = p.payload or {}\n",
    "        print(f\"‚Ä¢ score={p.score:.4f} | archivo={pl.get('archivo')} | par_idx={pl.get('par_idx')} | len={pl.get('char_len')}\\n  ‚Äú{(pl.get('fragmento') or '')[:180]}...‚Äù\\n\")\n",
    "\n",
    "# Neo4j: conteo por entrevista\n",
    "def graph_counts():\n",
    "    with neo.session(database=NEO4J_DATABASE) as s:\n",
    "        data = s.run(\"\"\"\n",
    "            MATCH (e:Entrevista)-[:TIENE_FRAGMENTO]->(f:Fragmento)\n",
    "            RETURN e.nombre AS entrevista, count(f) AS n\n",
    "            ORDER BY n DESC\n",
    "        \"\"\").data()\n",
    "    for row in data:\n",
    "        print(f\"{row['entrevista']}: {row['n']} fragmentos\")\n",
    "\n",
    "\n",
    "# Postgres: muestra 3 filas\n",
    "def sample_pg(n: int = 3):\n",
    "    pg_cur.execute(\"SELECT id, archivo, par_idx, char_len FROM entrevista_fragmentos LIMIT %s\", (n,))\n",
    "    for r in pg_cur.fetchall():\n",
    "        print(r)\n",
    "\n",
    "# Ejemplos (descomenta tras ingesta):\n",
    "# semantic_search(\"conflictos de drenaje y crecimiento urbano\", top_k=5)\n",
    "# graph_counts()\n",
    "# sample_pg(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f074de1c",
   "metadata": {},
   "source": [
    "## 10. An√°lisis cualitativo asistido (Etapas 0‚Äì9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "QUAL_SYSTEM_PROMPT = \"\"\"Eres un asistente AI experto en metodolog√≠a cualitativa y an√°lisis de entrevistas.\n",
    "Se te suministrar√°n entrevistas transcritas previamente revisadas y verificadas en su fidelidad.\n",
    "Tu tarea es guiar el an√°lisis cualitativo siguiendo un enfoque sistem√°tico en varias etapas, desde la preparaci√≥n hasta la estructuraci√≥n del informe final.\n",
    "\n",
    "Instrucciones:\n",
    "Etapa 0 ‚Äì Preparaci√≥n, Reflexividad y Configuraci√≥n del An√°lisis: Revisa el texto buscando incoherencias en la transcripci√≥n.\n",
    "Etapa 1 ‚Äì Transcripci√≥n y resumen: Verifica literalidad y elabora un resumen breve.\n",
    "Etapa 2 ‚Äì An√°lisis Descriptivo Inicial: Resume primeras impresiones y temas superficiales. Justifica c√≥digos iniciales.\n",
    "Etapa 3 ‚Äì Codificaci√≥n Abierta: Prop√≥n c√≥digos y citas (matriz).\n",
    "Etapa 4 ‚Äì Codificaci√≥n Axial: Agrupa en categor√≠as axiales, con notas/memos y relaciones.\n",
    "Etapa 5 ‚Äì Codificaci√≥n Selectiva: Identifica el n√∫cleo tem√°tico integrador.\n",
    "Etapa 6 ‚Äì An√°lisis Tem√°tico Transversal: Compara categor√≠as por entrevista, se√±alando convergencias/divergencias y variaciones por rol/g√©nero/tiempo.\n",
    "Etapa 7 ‚Äì Modelo Explicativo: Prop√≥n un diagrama ASCII (mapa conceptual) con relaciones entre problemas urban√≠sticos, participaci√≥n y transformaci√≥n hist√≥rica.\n",
    "Etapa 8 ‚Äì Verificaci√≥n/Validaci√≥n/Saturaci√≥n: Eval√∫a saturaci√≥n, triangulaci√≥n y factibilidad de member checking.\n",
    "Etapa 9 ‚Äì Hacia el Informe Final: Esboza estructura de informe con referencias a matrices, citas variadas (anonimizadas), limitaciones y recomendaciones.\n",
    "\n",
    "Devuelve SIEMPRE un JSON *v√°lido* con esta forma m√≠nima:\n",
    "{\n",
    "  \"etapa0_observaciones\": \"...\",\n",
    "  \"etapa1_resumen\": \"...\",\n",
    "  \"etapa2_descriptivo\": { \"impresiones\": \"...\", \"lista_codigos_iniciales\": [\"...\"] },\n",
    "  \"etapa3_matriz_abierta\": [ { \"codigo\": \"...\", \"cita\": \"...\", \"fuente\": \"Entrevistado/a\" } ],\n",
    "  \"etapa4_axial\": [ { \"categoria\": \"...\", \"codigos\": [\"...\"], \"relaciones\": [\"A->B\", \"B<->C\"], \"memo\": \"...\" } ],\n",
    "  \"etapa5_selectiva\": { \"nucleo\": \"...\", \"narrativa\": \"...\" },\n",
    "  \"etapa6_transversal\": { \"convergencias\": \"...\", \"divergencias\": \"...\", \"variaciones\": \"...\" },\n",
    "  \"etapa7_modelo_ascii\": \"Texto de diagrama\",\n",
    "  \"etapa8_validacion\": { \"saturacion\": \"...\", \"triangulacion\": [\"...\"], \"member_checking\": \"...\" },\n",
    "  \"etapa9_borrador_informe\": \"Esquema de informe\"\n",
    "}\n",
    "Usa citas literales cortas (‚â§ 40‚Äì60 palabras). Mant√©n anonimizaci√≥n.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e62b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_llm_chat_json(system_prompt: str, user_prompt: str, temperature: float = 0.2, max_tokens: int = 1800) -> dict:\n",
    "    msg = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    try:\n",
    "        comp = aoai.chat.completions.create(\n",
    "            model=DEP_CHAT,\n",
    "            messages=msg,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        txt = comp.choices[0].message.content\n",
    "        # Intentar extraer JSON ‚Äì se tolera texto extra\n",
    "        start = txt.find(\"{\"); end = txt.rfind(\"}\")\n",
    "        if start != -1 and end != -1 and end > start:\n",
    "            txt = txt[start:end+1]\n",
    "        return json.loads(txt)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå LLM error:\", e)\n",
    "        return {}\n",
    "\n",
    "def analyze_interview_text(text: str, fuente: str) -> dict:\n",
    "    # Acota longitud si es necesario; para contextos largos se puede trocear y resumir primero\n",
    "    user_prompt = f\"\"\"Analiza la siguiente transcripci√≥n (fuente: {fuente}) siguiendo las Etapas 0‚Äì9. \n",
    "Devuelve SOLO el JSON. \n",
    "Texto:\n",
    "\"\"\"{text}\"\"\"\n",
    "\"\"\"\n",
    "    return call_llm_chat_json(QUAL_SYSTEM_PROMPT, user_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61da513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def matriz_etapa3(json_out: dict) -> pd.DataFrame:\n",
    "    rows = json_out.get(\"etapa3_matriz_abierta\", []) or []\n",
    "    df = pd.DataFrame(rows, columns=[\"codigo\", \"cita\", \"fuente\"])\n",
    "    df.rename(columns={\"codigo\":\"C√≥digo Abierto\", \"cita\":\"Cita Textual / Ejemplo Relevante\", \"fuente\":\"Fuente (Entrevistado/a)\"}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def matriz_etapa4(json_out: dict) -> pd.DataFrame:\n",
    "    rows = json_out.get(\"etapa4_axial\", []) or []\n",
    "    # Expandir filas por c√≥digo para facilitar tabla relacional\n",
    "    exp = []\n",
    "    for r in rows:\n",
    "        categoria = r.get(\"categoria\",\"\")\n",
    "        memo = r.get(\"memo\",\"\")\n",
    "        relaciones = \"; \".join(r.get(\"relaciones\", []) or [])\n",
    "        for c in r.get(\"codigos\", []) or []:\n",
    "            exp.append({\"Categor√≠a Axial\": categoria, \"C√≥digo Abierto\": c, \"Relaciones\": relaciones, \"Notas/Memos\": memo})\n",
    "    df = pd.DataFrame(exp, columns=[\"Categor√≠a Axial\", \"C√≥digo Abierto\", \"Relaciones\", \"Notas/Memos\"])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca4aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_modelo_ascii(json_out: dict):\n",
    "    print(json_out.get(\"etapa7_modelo_ascii\", \"(sin diagrama)\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f99d1",
   "metadata": {},
   "source": [
    "### Ejemplo: correr an√°lisis sobre una entrevista (despu√©s de la ingesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeaaa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carga una entrevista para an√°lisis (reemplaza la ruta)\n",
    "# path = r\"C:\\ruta\\a\\tu\\Entrevistas\\Entre1.docx\"\n",
    "# text = \"\\n\".join(read_paragraphs_from_docx(path))\n",
    "# out = analyze_interview_text(text, fuente=os.path.basename(path))\n",
    "\n",
    "# # Visualizar matrices\n",
    "# df3 = matriz_etapa3(out); df4 = matriz_etapa4(out)\n",
    "# display(df3.head(10))\n",
    "# display(df4.head(10))\n",
    "# print_modelo_ascii(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126092b6",
   "metadata": {},
   "source": [
    "## 11. (Opcional) Persistir matrices de an√°lisis en PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a10949",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensure_analysis_tables():\n",
    "    pg_cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS analisis_codigos_abiertos (\n",
    "        archivo TEXT NOT NULL,\n",
    "        codigo TEXT NOT NULL,\n",
    "        cita TEXT NOT NULL,\n",
    "        fuente TEXT NOT NULL,\n",
    "        created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n",
    "    );\n",
    "    CREATE TABLE IF NOT EXISTS analisis_axial (\n",
    "        archivo TEXT NOT NULL,\n",
    "        categoria TEXT NOT NULL,\n",
    "        codigo TEXT NOT NULL,\n",
    "        relaciones TEXT,\n",
    "        memo TEXT,\n",
    "        created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n",
    "    );\n",
    "    \"\"\")\n",
    "    pg.commit()\n",
    "\n",
    "def persist_analysis(archivo: str, json_out: dict):\n",
    "    ensure_analysis_tables()\n",
    "    # Etapa 3\n",
    "    rows3 = json_out.get(\"etapa3_matriz_abierta\", []) or []\n",
    "    if rows3:\n",
    "        execute_values(pg_cur,\n",
    "            \"INSERT INTO analisis_codigos_abiertos (archivo, codigo, cita, fuente) VALUES %s\",\n",
    "            [(archivo, r.get(\"codigo\",\"\"), r.get(\"cita\",\"\"), r.get(\"fuente\",\"\")) for r in rows3]\n",
    "        )\n",
    "    # Etapa 4\n",
    "    rows4 = json_out.get(\"etapa4_axial\", []) or []\n",
    "    exp4 = []\n",
    "    for r in rows4:\n",
    "        categoria = r.get(\"categoria\",\"\"); memo = r.get(\"memo\",\"\")\n",
    "        relaciones = \"; \".join(r.get(\"relaciones\", []) or [])\n",
    "        for c in r.get(\"codigos\", []) or []:\n",
    "            exp4.append((archivo, categoria, c, relaciones, memo))\n",
    "    if exp4:\n",
    "        execute_values(pg_cur,\n",
    "            \"INSERT INTO analisis_axial (archivo, categoria, codigo, relaciones, memo) VALUES %s\",\n",
    "            exp4\n",
    "        )\n",
    "    pg.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8752e90f",
   "metadata": {},
   "source": [
    "## 12. Cierre de conexiones (cuando termines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5321836",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    pg_cur.close(); pg.close()\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    neo.close()\n",
    "except Exception:\n",
    "    pass\n",
    "print(\"üîö Conexiones cerradas.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
